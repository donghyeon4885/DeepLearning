{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5adf0366",
   "metadata": {},
   "source": [
    "# chap 14 모델 성능 향상시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36009d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./data/wine.csv',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a671ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18bb227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae20a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cda7cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 3s 65ms/step - loss: 1.0532 - accuracy: 0.7524 - val_loss: 0.4967 - val_accuracy: 0.7654\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4350 - accuracy: 0.7665 - val_loss: 0.4088 - val_accuracy: 0.8269\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3827 - accuracy: 0.7934 - val_loss: 0.3515 - val_accuracy: 0.7869\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3583 - accuracy: 0.7934 - val_loss: 0.3219 - val_accuracy: 0.8323\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.8504 - val_loss: 0.3088 - val_accuracy: 0.8638\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3135 - accuracy: 0.8581 - val_loss: 0.2928 - val_accuracy: 0.8569\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2988 - accuracy: 0.8689 - val_loss: 0.2794 - val_accuracy: 0.9023\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.2865 - accuracy: 0.8966 - val_loss: 0.2672 - val_accuracy: 0.9062\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2756 - accuracy: 0.8971 - val_loss: 0.2572 - val_accuracy: 0.9162\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2646 - accuracy: 0.9107 - val_loss: 0.2470 - val_accuracy: 0.9238\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.2538 - accuracy: 0.9171 - val_loss: 0.2368 - val_accuracy: 0.9277\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2435 - accuracy: 0.9235 - val_loss: 0.2267 - val_accuracy: 0.9338\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2340 - accuracy: 0.9312 - val_loss: 0.2171 - val_accuracy: 0.9346\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2257 - accuracy: 0.9281 - val_loss: 0.2107 - val_accuracy: 0.9354\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2195 - accuracy: 0.9338 - val_loss: 0.2062 - val_accuracy: 0.9369\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2152 - accuracy: 0.9346 - val_loss: 0.2031 - val_accuracy: 0.9362\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2119 - accuracy: 0.9330 - val_loss: 0.2000 - val_accuracy: 0.9377\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 0.2102 - accuracy: 0.9335 - val_loss: 0.1986 - val_accuracy: 0.9362\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 0.2070 - accuracy: 0.9351 - val_loss: 0.1958 - val_accuracy: 0.9354\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2049 - accuracy: 0.9346 - val_loss: 0.1944 - val_accuracy: 0.9354\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2043 - accuracy: 0.9356 - val_loss: 0.1934 - val_accuracy: 0.9385\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2047 - accuracy: 0.9346 - val_loss: 0.1927 - val_accuracy: 0.9362\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.2009 - accuracy: 0.9338 - val_loss: 0.1900 - val_accuracy: 0.9354\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1986 - accuracy: 0.9351 - val_loss: 0.1889 - val_accuracy: 0.9362\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1974 - accuracy: 0.9356 - val_loss: 0.1878 - val_accuracy: 0.9362\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1961 - accuracy: 0.9369 - val_loss: 0.1880 - val_accuracy: 0.9346\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1949 - accuracy: 0.9364 - val_loss: 0.1855 - val_accuracy: 0.9369\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1932 - accuracy: 0.9364 - val_loss: 0.1840 - val_accuracy: 0.9377\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1915 - accuracy: 0.9369 - val_loss: 0.1825 - val_accuracy: 0.9385\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1904 - accuracy: 0.9374 - val_loss: 0.1819 - val_accuracy: 0.9385\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1889 - accuracy: 0.9382 - val_loss: 0.1801 - val_accuracy: 0.9385\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1868 - accuracy: 0.9384 - val_loss: 0.1780 - val_accuracy: 0.9385\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1844 - accuracy: 0.9387 - val_loss: 0.1760 - val_accuracy: 0.9385\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1828 - accuracy: 0.9371 - val_loss: 0.1751 - val_accuracy: 0.9392\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1802 - accuracy: 0.9405 - val_loss: 0.1733 - val_accuracy: 0.9400\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1787 - accuracy: 0.9412 - val_loss: 0.1729 - val_accuracy: 0.9392\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1786 - accuracy: 0.9394 - val_loss: 0.1705 - val_accuracy: 0.9408\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1768 - accuracy: 0.9412 - val_loss: 0.1696 - val_accuracy: 0.9408\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1752 - accuracy: 0.9407 - val_loss: 0.1688 - val_accuracy: 0.9408\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1738 - accuracy: 0.9407 - val_loss: 0.1677 - val_accuracy: 0.9408\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1720 - accuracy: 0.9418 - val_loss: 0.1667 - val_accuracy: 0.9415\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1708 - accuracy: 0.9415 - val_loss: 0.1658 - val_accuracy: 0.9408\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1702 - accuracy: 0.9412 - val_loss: 0.1647 - val_accuracy: 0.9400\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1688 - accuracy: 0.9425 - val_loss: 0.1634 - val_accuracy: 0.9438\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1670 - accuracy: 0.9420 - val_loss: 0.1625 - val_accuracy: 0.9431\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1656 - accuracy: 0.9425 - val_loss: 0.1618 - val_accuracy: 0.9415\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1654 - accuracy: 0.9423 - val_loss: 0.1608 - val_accuracy: 0.9423\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1659 - accuracy: 0.9433 - val_loss: 0.1622 - val_accuracy: 0.9454\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1645 - accuracy: 0.9430 - val_loss: 0.1601 - val_accuracy: 0.9423\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1623 - accuracy: 0.9425 - val_loss: 0.1587 - val_accuracy: 0.9462\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ad551c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.9362\n",
      "Test loss :  0.17946872115135193   Test accuracy :  0.9361538290977478\n"
     ]
    }
   ],
   "source": [
    "#  모델 결과 출력\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"Test loss : \", score[0], \"  Test accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09f1e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint를 통해 모델 업데이트\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c732e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./data/model/all\\01-0.7846.hdf5\n",
      "\n",
      "Epoch 2: saving model to ./data/model/all\\02-0.7677.hdf5\n",
      "\n",
      "Epoch 3: saving model to ./data/model/all\\03-0.7862.hdf5\n",
      "\n",
      "Epoch 4: saving model to ./data/model/all\\04-0.8200.hdf5\n",
      "\n",
      "Epoch 5: saving model to ./data/model/all\\05-0.8508.hdf5\n",
      "\n",
      "Epoch 6: saving model to ./data/model/all\\06-0.9031.hdf5\n",
      "\n",
      "Epoch 7: saving model to ./data/model/all\\07-0.9300.hdf5\n",
      "\n",
      "Epoch 8: saving model to ./data/model/all\\08-0.9285.hdf5\n",
      "\n",
      "Epoch 9: saving model to ./data/model/all\\09-0.9277.hdf5\n",
      "\n",
      "Epoch 10: saving model to ./data/model/all\\10-0.9354.hdf5\n",
      "\n",
      "Epoch 11: saving model to ./data/model/all\\11-0.9346.hdf5\n",
      "\n",
      "Epoch 12: saving model to ./data/model/all\\12-0.9362.hdf5\n",
      "\n",
      "Epoch 13: saving model to ./data/model/all\\13-0.9369.hdf5\n",
      "\n",
      "Epoch 14: saving model to ./data/model/all\\14-0.9369.hdf5\n",
      "\n",
      "Epoch 15: saving model to ./data/model/all\\15-0.9369.hdf5\n",
      "\n",
      "Epoch 16: saving model to ./data/model/all\\16-0.9369.hdf5\n",
      "\n",
      "Epoch 17: saving model to ./data/model/all\\17-0.9385.hdf5\n",
      "\n",
      "Epoch 18: saving model to ./data/model/all\\18-0.9377.hdf5\n",
      "\n",
      "Epoch 19: saving model to ./data/model/all\\19-0.9377.hdf5\n",
      "\n",
      "Epoch 20: saving model to ./data/model/all\\20-0.9385.hdf5\n",
      "\n",
      "Epoch 21: saving model to ./data/model/all\\21-0.9377.hdf5\n",
      "\n",
      "Epoch 22: saving model to ./data/model/all\\22-0.9385.hdf5\n",
      "\n",
      "Epoch 23: saving model to ./data/model/all\\23-0.9400.hdf5\n",
      "\n",
      "Epoch 24: saving model to ./data/model/all\\24-0.9392.hdf5\n",
      "\n",
      "Epoch 25: saving model to ./data/model/all\\25-0.9408.hdf5\n",
      "\n",
      "Epoch 26: saving model to ./data/model/all\\26-0.9392.hdf5\n",
      "\n",
      "Epoch 27: saving model to ./data/model/all\\27-0.9415.hdf5\n",
      "\n",
      "Epoch 28: saving model to ./data/model/all\\28-0.9423.hdf5\n",
      "\n",
      "Epoch 29: saving model to ./data/model/all\\29-0.9431.hdf5\n",
      "\n",
      "Epoch 30: saving model to ./data/model/all\\30-0.9431.hdf5\n",
      "\n",
      "Epoch 31: saving model to ./data/model/all\\31-0.9431.hdf5\n",
      "\n",
      "Epoch 32: saving model to ./data/model/all\\32-0.9446.hdf5\n",
      "\n",
      "Epoch 33: saving model to ./data/model/all\\33-0.9454.hdf5\n",
      "\n",
      "Epoch 34: saving model to ./data/model/all\\34-0.9462.hdf5\n",
      "\n",
      "Epoch 35: saving model to ./data/model/all\\35-0.9477.hdf5\n",
      "\n",
      "Epoch 36: saving model to ./data/model/all\\36-0.9469.hdf5\n",
      "\n",
      "Epoch 37: saving model to ./data/model/all\\37-0.9515.hdf5\n",
      "\n",
      "Epoch 38: saving model to ./data/model/all\\38-0.9454.hdf5\n",
      "\n",
      "Epoch 39: saving model to ./data/model/all\\39-0.9531.hdf5\n",
      "\n",
      "Epoch 40: saving model to ./data/model/all\\40-0.9538.hdf5\n",
      "\n",
      "Epoch 41: saving model to ./data/model/all\\41-0.9500.hdf5\n",
      "\n",
      "Epoch 42: saving model to ./data/model/all\\42-0.9554.hdf5\n",
      "\n",
      "Epoch 43: saving model to ./data/model/all\\43-0.9546.hdf5\n",
      "\n",
      "Epoch 44: saving model to ./data/model/all\\44-0.9562.hdf5\n",
      "\n",
      "Epoch 45: saving model to ./data/model/all\\45-0.9538.hdf5\n",
      "\n",
      "Epoch 46: saving model to ./data/model/all\\46-0.9515.hdf5\n",
      "\n",
      "Epoch 47: saving model to ./data/model/all\\47-0.9569.hdf5\n",
      "\n",
      "Epoch 48: saving model to ./data/model/all\\48-0.9631.hdf5\n",
      "\n",
      "Epoch 49: saving model to ./data/model/all\\49-0.9562.hdf5\n",
      "\n",
      "Epoch 50: saving model to ./data/model/all\\50-0.9554.hdf5\n",
      "\n",
      "Epoch 51: saving model to ./data/model/all\\51-0.9600.hdf5\n",
      "\n",
      "Epoch 52: saving model to ./data/model/all\\52-0.9638.hdf5\n",
      "\n",
      "Epoch 53: saving model to ./data/model/all\\53-0.9585.hdf5\n",
      "\n",
      "Epoch 54: saving model to ./data/model/all\\54-0.9631.hdf5\n",
      "\n",
      "Epoch 55: saving model to ./data/model/all\\55-0.9662.hdf5\n",
      "\n",
      "Epoch 56: saving model to ./data/model/all\\56-0.9662.hdf5\n",
      "\n",
      "Epoch 57: saving model to ./data/model/all\\57-0.9677.hdf5\n",
      "\n",
      "Epoch 58: saving model to ./data/model/all\\58-0.9631.hdf5\n",
      "\n",
      "Epoch 59: saving model to ./data/model/all\\59-0.9646.hdf5\n",
      "\n",
      "Epoch 60: saving model to ./data/model/all\\60-0.9654.hdf5\n",
      "\n",
      "Epoch 61: saving model to ./data/model/all\\61-0.9646.hdf5\n",
      "\n",
      "Epoch 62: saving model to ./data/model/all\\62-0.9685.hdf5\n",
      "\n",
      "Epoch 63: saving model to ./data/model/all\\63-0.9646.hdf5\n",
      "\n",
      "Epoch 64: saving model to ./data/model/all\\64-0.9700.hdf5\n",
      "\n",
      "Epoch 65: saving model to ./data/model/all\\65-0.9700.hdf5\n",
      "\n",
      "Epoch 66: saving model to ./data/model/all\\66-0.9654.hdf5\n",
      "\n",
      "Epoch 67: saving model to ./data/model/all\\67-0.9685.hdf5\n",
      "\n",
      "Epoch 68: saving model to ./data/model/all\\68-0.9692.hdf5\n",
      "\n",
      "Epoch 69: saving model to ./data/model/all\\69-0.9700.hdf5\n",
      "\n",
      "Epoch 70: saving model to ./data/model/all\\70-0.9700.hdf5\n",
      "\n",
      "Epoch 71: saving model to ./data/model/all\\71-0.9700.hdf5\n",
      "\n",
      "Epoch 72: saving model to ./data/model/all\\72-0.9708.hdf5\n",
      "\n",
      "Epoch 73: saving model to ./data/model/all\\73-0.9708.hdf5\n",
      "\n",
      "Epoch 74: saving model to ./data/model/all\\74-0.9700.hdf5\n",
      "\n",
      "Epoch 75: saving model to ./data/model/all\\75-0.9708.hdf5\n",
      "\n",
      "Epoch 76: saving model to ./data/model/all\\76-0.9700.hdf5\n",
      "\n",
      "Epoch 77: saving model to ./data/model/all\\77-0.9700.hdf5\n",
      "\n",
      "Epoch 78: saving model to ./data/model/all\\78-0.9708.hdf5\n",
      "\n",
      "Epoch 79: saving model to ./data/model/all\\79-0.9708.hdf5\n",
      "\n",
      "Epoch 80: saving model to ./data/model/all\\80-0.9708.hdf5\n",
      "\n",
      "Epoch 81: saving model to ./data/model/all\\81-0.9692.hdf5\n",
      "\n",
      "Epoch 82: saving model to ./data/model/all\\82-0.9700.hdf5\n",
      "\n",
      "Epoch 83: saving model to ./data/model/all\\83-0.9731.hdf5\n",
      "\n",
      "Epoch 84: saving model to ./data/model/all\\84-0.9731.hdf5\n",
      "\n",
      "Epoch 85: saving model to ./data/model/all\\85-0.9723.hdf5\n",
      "\n",
      "Epoch 86: saving model to ./data/model/all\\86-0.9723.hdf5\n",
      "\n",
      "Epoch 87: saving model to ./data/model/all\\87-0.9715.hdf5\n",
      "\n",
      "Epoch 88: saving model to ./data/model/all\\88-0.9723.hdf5\n",
      "\n",
      "Epoch 89: saving model to ./data/model/all\\89-0.9731.hdf5\n",
      "\n",
      "Epoch 90: saving model to ./data/model/all\\90-0.9731.hdf5\n",
      "\n",
      "Epoch 91: saving model to ./data/model/all\\91-0.9731.hdf5\n",
      "\n",
      "Epoch 92: saving model to ./data/model/all\\92-0.9723.hdf5\n",
      "\n",
      "Epoch 93: saving model to ./data/model/all\\93-0.9715.hdf5\n",
      "\n",
      "Epoch 94: saving model to ./data/model/all\\94-0.9723.hdf5\n",
      "\n",
      "Epoch 95: saving model to ./data/model/all\\95-0.9738.hdf5\n",
      "\n",
      "Epoch 96: saving model to ./data/model/all\\96-0.9731.hdf5\n",
      "\n",
      "Epoch 97: saving model to ./data/model/all\\97-0.9738.hdf5\n",
      "\n",
      "Epoch 98: saving model to ./data/model/all\\98-0.9715.hdf5\n",
      "\n",
      "Epoch 99: saving model to ./data/model/all\\99-0.9715.hdf5\n",
      "\n",
      "Epoch 100: saving model to ./data/model/all\\100-0.9738.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb440079d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model= Sequential()\n",
    "model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# epoch 실행시 마다 모델을 파일로 저장\n",
    "model_path = './data/model/all/{epoch:02d}-{val_accuracy:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=True)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행 : callbacks 를 설정 \n",
    "model.fit(X_train, y_train, epochs=100, batch_size=500, validation_split=0.25,\n",
    "         callbacks=[checkpointer], verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77056d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model=Sequential()\n",
    "model.add(Dense(30,input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(12,activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 모델 실행\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9ab636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "0.9792147874832153\n"
     ]
    }
   ],
   "source": [
    "print(model.history.history['accuracy'].index(max(model.history.history['accuracy'])))\n",
    "print(max(model.history.history['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f5cff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 확인 ( 에러 -> 손실함수의 결과 )\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "033d3bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss=hist_df['val_loss']\n",
    "y_loss=hist_df['loss']\n",
    "\n",
    "x_len = np.arange(len(y_vloss))\n",
    "plt.plot(x_len, y_vloss, \"o\", markersize= 0.5, c='red', label='Test_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", markersize= 0.1,c='blue', label='Train_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e389d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  중단점 설정\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fab1e951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "8/8 [==============================] - 4s 95ms/step - loss: 12.4587 - accuracy: 0.2476 - val_loss: 9.4032 - val_accuracy: 0.2346\n",
      "Epoch 2/2000\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 6.7001 - accuracy: 0.2471 - val_loss: 3.8469 - val_accuracy: 0.2338\n",
      "Epoch 3/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8882 - accuracy: 0.3911 - val_loss: 0.4063 - val_accuracy: 0.8400\n",
      "Epoch 4/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3991 - accuracy: 0.8368 - val_loss: 0.4430 - val_accuracy: 0.8308\n",
      "Epoch 5/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4850 - accuracy: 0.8317 - val_loss: 0.4725 - val_accuracy: 0.8431\n",
      "Epoch 6/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4643 - accuracy: 0.8548 - val_loss: 0.4056 - val_accuracy: 0.8700\n",
      "Epoch 7/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3827 - accuracy: 0.8802 - val_loss: 0.3249 - val_accuracy: 0.8985\n",
      "Epoch 8/2000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.3096 - accuracy: 0.9015 - val_loss: 0.2755 - val_accuracy: 0.9123\n",
      "Epoch 9/2000\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.2789 - accuracy: 0.9107 - val_loss: 0.2671 - val_accuracy: 0.9200\n",
      "Epoch 10/2000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.2623 - accuracy: 0.9140 - val_loss: 0.2432 - val_accuracy: 0.9215\n",
      "Epoch 11/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2468 - accuracy: 0.9161 - val_loss: 0.2320 - val_accuracy: 0.9246\n",
      "Epoch 12/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.2355 - accuracy: 0.9181 - val_loss: 0.2225 - val_accuracy: 0.9269\n",
      "Epoch 13/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2290 - accuracy: 0.9192 - val_loss: 0.2156 - val_accuracy: 0.9262\n",
      "Epoch 14/2000\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.2229 - accuracy: 0.9217 - val_loss: 0.2104 - val_accuracy: 0.9292\n",
      "Epoch 15/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.2175 - accuracy: 0.9240 - val_loss: 0.2068 - val_accuracy: 0.9300\n",
      "Epoch 16/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2129 - accuracy: 0.9274 - val_loss: 0.2031 - val_accuracy: 0.9300\n",
      "Epoch 17/2000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.2087 - accuracy: 0.9281 - val_loss: 0.1985 - val_accuracy: 0.9308\n",
      "Epoch 18/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.2052 - accuracy: 0.9294 - val_loss: 0.1946 - val_accuracy: 0.9331\n",
      "Epoch 19/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.2019 - accuracy: 0.9310 - val_loss: 0.1906 - val_accuracy: 0.9338\n",
      "Epoch 20/2000\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.1987 - accuracy: 0.9320 - val_loss: 0.1866 - val_accuracy: 0.9354\n",
      "Epoch 21/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1945 - accuracy: 0.9358 - val_loss: 0.1831 - val_accuracy: 0.9369\n",
      "Epoch 22/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1899 - accuracy: 0.9384 - val_loss: 0.1814 - val_accuracy: 0.9354\n",
      "Epoch 23/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1868 - accuracy: 0.9407 - val_loss: 0.1781 - val_accuracy: 0.9385\n",
      "Epoch 24/2000\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.1838 - accuracy: 0.9410 - val_loss: 0.1762 - val_accuracy: 0.9408\n",
      "Epoch 25/2000\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.1813 - accuracy: 0.9392 - val_loss: 0.1750 - val_accuracy: 0.9392\n",
      "Epoch 26/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1802 - accuracy: 0.9425 - val_loss: 0.1740 - val_accuracy: 0.9385\n",
      "Epoch 27/2000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.1783 - accuracy: 0.9400 - val_loss: 0.1704 - val_accuracy: 0.9400\n",
      "Epoch 28/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1751 - accuracy: 0.9405 - val_loss: 0.1675 - val_accuracy: 0.9408\n",
      "Epoch 29/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1692 - accuracy: 0.9405 - val_loss: 0.1631 - val_accuracy: 0.9400\n",
      "Epoch 30/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1627 - accuracy: 0.9410 - val_loss: 0.1606 - val_accuracy: 0.9415\n",
      "Epoch 31/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1591 - accuracy: 0.9420 - val_loss: 0.1592 - val_accuracy: 0.9423\n",
      "Epoch 32/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1575 - accuracy: 0.9425 - val_loss: 0.1602 - val_accuracy: 0.9438\n",
      "Epoch 33/2000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.1556 - accuracy: 0.9418 - val_loss: 0.1564 - val_accuracy: 0.9446\n",
      "Epoch 34/2000\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.1522 - accuracy: 0.9435 - val_loss: 0.1542 - val_accuracy: 0.9446\n",
      "Epoch 35/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1507 - accuracy: 0.9453 - val_loss: 0.1531 - val_accuracy: 0.9446\n",
      "Epoch 36/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1497 - accuracy: 0.9456 - val_loss: 0.1530 - val_accuracy: 0.9462\n",
      "Epoch 37/2000\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.1469 - accuracy: 0.9451 - val_loss: 0.1503 - val_accuracy: 0.9462\n",
      "Epoch 38/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1455 - accuracy: 0.9479 - val_loss: 0.1497 - val_accuracy: 0.9438\n",
      "Epoch 39/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1434 - accuracy: 0.9474 - val_loss: 0.1481 - val_accuracy: 0.9454\n",
      "Epoch 40/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1412 - accuracy: 0.9487 - val_loss: 0.1469 - val_accuracy: 0.9477\n",
      "Epoch 41/2000\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.1393 - accuracy: 0.9492 - val_loss: 0.1467 - val_accuracy: 0.9485\n",
      "Epoch 42/2000\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.1383 - accuracy: 0.9479 - val_loss: 0.1454 - val_accuracy: 0.9469\n",
      "Epoch 43/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1361 - accuracy: 0.9489 - val_loss: 0.1445 - val_accuracy: 0.9462\n",
      "Epoch 44/2000\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.1350 - accuracy: 0.9489 - val_loss: 0.1431 - val_accuracy: 0.9485\n",
      "Epoch 45/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1329 - accuracy: 0.9512 - val_loss: 0.1424 - val_accuracy: 0.9477\n",
      "Epoch 46/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1312 - accuracy: 0.9492 - val_loss: 0.1427 - val_accuracy: 0.9477\n",
      "Epoch 47/2000\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.1282 - accuracy: 0.9533 - val_loss: 0.1400 - val_accuracy: 0.9477\n",
      "Epoch 48/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1261 - accuracy: 0.9538 - val_loss: 0.1427 - val_accuracy: 0.9492\n",
      "Epoch 49/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1245 - accuracy: 0.9507 - val_loss: 0.1388 - val_accuracy: 0.9485\n",
      "Epoch 50/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1229 - accuracy: 0.9525 - val_loss: 0.1391 - val_accuracy: 0.9492\n",
      "Epoch 51/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1211 - accuracy: 0.9546 - val_loss: 0.1362 - val_accuracy: 0.9477\n",
      "Epoch 52/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1214 - accuracy: 0.9541 - val_loss: 0.1360 - val_accuracy: 0.9500\n",
      "Epoch 53/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1219 - accuracy: 0.9551 - val_loss: 0.1407 - val_accuracy: 0.9492\n",
      "Epoch 54/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1194 - accuracy: 0.9551 - val_loss: 0.1337 - val_accuracy: 0.9477\n",
      "Epoch 55/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1191 - accuracy: 0.9538 - val_loss: 0.1613 - val_accuracy: 0.9462\n",
      "Epoch 56/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1317 - accuracy: 0.9530 - val_loss: 0.1350 - val_accuracy: 0.9531\n",
      "Epoch 57/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1305 - accuracy: 0.9515 - val_loss: 0.1466 - val_accuracy: 0.9523\n",
      "Epoch 58/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.1196 - accuracy: 0.9595 - val_loss: 0.1364 - val_accuracy: 0.9515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1161 - accuracy: 0.9566 - val_loss: 0.1323 - val_accuracy: 0.9546\n",
      "Epoch 60/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1175 - accuracy: 0.9571 - val_loss: 0.1386 - val_accuracy: 0.9523\n",
      "Epoch 61/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1144 - accuracy: 0.9571 - val_loss: 0.1332 - val_accuracy: 0.9515\n",
      "Epoch 62/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1112 - accuracy: 0.9587 - val_loss: 0.1289 - val_accuracy: 0.9523\n",
      "Epoch 63/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1105 - accuracy: 0.9574 - val_loss: 0.1301 - val_accuracy: 0.9531\n",
      "Epoch 64/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1083 - accuracy: 0.9597 - val_loss: 0.1357 - val_accuracy: 0.9508\n",
      "Epoch 65/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1120 - accuracy: 0.9582 - val_loss: 0.1272 - val_accuracy: 0.9492\n",
      "Epoch 66/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1058 - accuracy: 0.9602 - val_loss: 0.1281 - val_accuracy: 0.9531\n",
      "Epoch 67/2000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.1063 - accuracy: 0.9610 - val_loss: 0.1263 - val_accuracy: 0.9515\n",
      "Epoch 68/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1053 - accuracy: 0.9618 - val_loss: 0.1261 - val_accuracy: 0.9531\n",
      "Epoch 69/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1037 - accuracy: 0.9597 - val_loss: 0.1262 - val_accuracy: 0.9523\n",
      "Epoch 70/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1036 - accuracy: 0.9610 - val_loss: 0.1257 - val_accuracy: 0.9531\n",
      "Epoch 71/2000\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.1020 - accuracy: 0.9613 - val_loss: 0.1241 - val_accuracy: 0.9531\n",
      "Epoch 72/2000\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.1007 - accuracy: 0.9615 - val_loss: 0.1234 - val_accuracy: 0.9562\n",
      "Epoch 73/2000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.1003 - accuracy: 0.9613 - val_loss: 0.1230 - val_accuracy: 0.9531\n",
      "Epoch 74/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0991 - accuracy: 0.9638 - val_loss: 0.1223 - val_accuracy: 0.9562\n",
      "Epoch 75/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0986 - accuracy: 0.9633 - val_loss: 0.1250 - val_accuracy: 0.9523\n",
      "Epoch 76/2000\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0987 - accuracy: 0.9620 - val_loss: 0.1222 - val_accuracy: 0.9531\n",
      "Epoch 77/2000\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0964 - accuracy: 0.9628 - val_loss: 0.1209 - val_accuracy: 0.9577\n",
      "Epoch 78/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0973 - accuracy: 0.9638 - val_loss: 0.1203 - val_accuracy: 0.9577\n",
      "Epoch 79/2000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0953 - accuracy: 0.9646 - val_loss: 0.1200 - val_accuracy: 0.9585\n",
      "Epoch 80/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0942 - accuracy: 0.9643 - val_loss: 0.1207 - val_accuracy: 0.9577\n",
      "Epoch 81/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0939 - accuracy: 0.9646 - val_loss: 0.1232 - val_accuracy: 0.9538\n",
      "Epoch 82/2000\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.0948 - accuracy: 0.9656 - val_loss: 0.1184 - val_accuracy: 0.9585\n",
      "Epoch 83/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0942 - accuracy: 0.9641 - val_loss: 0.1219 - val_accuracy: 0.9592\n",
      "Epoch 84/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0937 - accuracy: 0.9661 - val_loss: 0.1171 - val_accuracy: 0.9608\n",
      "Epoch 85/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0923 - accuracy: 0.9679 - val_loss: 0.1207 - val_accuracy: 0.9562\n",
      "Epoch 86/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0924 - accuracy: 0.9664 - val_loss: 0.1226 - val_accuracy: 0.9562\n",
      "Epoch 87/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0912 - accuracy: 0.9674 - val_loss: 0.1188 - val_accuracy: 0.9569\n",
      "Epoch 88/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0918 - accuracy: 0.9666 - val_loss: 0.1149 - val_accuracy: 0.9615\n",
      "Epoch 89/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0904 - accuracy: 0.9672 - val_loss: 0.1151 - val_accuracy: 0.9608\n",
      "Epoch 90/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0876 - accuracy: 0.9664 - val_loss: 0.1150 - val_accuracy: 0.9638\n",
      "Epoch 91/2000\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.0870 - accuracy: 0.9669 - val_loss: 0.1144 - val_accuracy: 0.9638\n",
      "Epoch 92/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0860 - accuracy: 0.9697 - val_loss: 0.1185 - val_accuracy: 0.9577\n",
      "Epoch 93/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0874 - accuracy: 0.9692 - val_loss: 0.1141 - val_accuracy: 0.9623\n",
      "Epoch 94/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0860 - accuracy: 0.9659 - val_loss: 0.1142 - val_accuracy: 0.9646\n",
      "Epoch 95/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0838 - accuracy: 0.9710 - val_loss: 0.1119 - val_accuracy: 0.9654\n",
      "Epoch 96/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0827 - accuracy: 0.9692 - val_loss: 0.1194 - val_accuracy: 0.9569\n",
      "Epoch 97/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0858 - accuracy: 0.9692 - val_loss: 0.1183 - val_accuracy: 0.9569\n",
      "Epoch 98/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0843 - accuracy: 0.9700 - val_loss: 0.1107 - val_accuracy: 0.9677\n",
      "Epoch 99/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0824 - accuracy: 0.9702 - val_loss: 0.1103 - val_accuracy: 0.9677\n",
      "Epoch 100/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0804 - accuracy: 0.9707 - val_loss: 0.1097 - val_accuracy: 0.9677\n",
      "Epoch 101/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0802 - accuracy: 0.9710 - val_loss: 0.1091 - val_accuracy: 0.9677\n",
      "Epoch 102/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0798 - accuracy: 0.9723 - val_loss: 0.1169 - val_accuracy: 0.9585\n",
      "Epoch 103/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0799 - accuracy: 0.9710 - val_loss: 0.1110 - val_accuracy: 0.9623\n",
      "Epoch 104/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0794 - accuracy: 0.9710 - val_loss: 0.1102 - val_accuracy: 0.9631\n",
      "Epoch 105/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0783 - accuracy: 0.9720 - val_loss: 0.1081 - val_accuracy: 0.9700\n",
      "Epoch 106/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0777 - accuracy: 0.9707 - val_loss: 0.1073 - val_accuracy: 0.9692\n",
      "Epoch 107/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0790 - accuracy: 0.9736 - val_loss: 0.1083 - val_accuracy: 0.9662\n",
      "Epoch 108/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0763 - accuracy: 0.9736 - val_loss: 0.1131 - val_accuracy: 0.9623\n",
      "Epoch 109/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0756 - accuracy: 0.9736 - val_loss: 0.1061 - val_accuracy: 0.9700\n",
      "Epoch 110/2000\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 0.0751 - accuracy: 0.9738 - val_loss: 0.1056 - val_accuracy: 0.9700\n",
      "Epoch 111/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0744 - accuracy: 0.9725 - val_loss: 0.1064 - val_accuracy: 0.9669\n",
      "Epoch 112/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0744 - accuracy: 0.9743 - val_loss: 0.1086 - val_accuracy: 0.9638\n",
      "Epoch 113/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0729 - accuracy: 0.9761 - val_loss: 0.1058 - val_accuracy: 0.9677\n",
      "Epoch 114/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0721 - accuracy: 0.9746 - val_loss: 0.1044 - val_accuracy: 0.9723\n",
      "Epoch 115/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0721 - accuracy: 0.9746 - val_loss: 0.1043 - val_accuracy: 0.9685\n",
      "Epoch 116/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0711 - accuracy: 0.9759 - val_loss: 0.1040 - val_accuracy: 0.9708\n",
      "Epoch 117/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0721 - accuracy: 0.9751 - val_loss: 0.1036 - val_accuracy: 0.9731\n",
      "Epoch 118/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0701 - accuracy: 0.9751 - val_loss: 0.1031 - val_accuracy: 0.9731\n",
      "Epoch 119/2000\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0700 - accuracy: 0.9769 - val_loss: 0.1029 - val_accuracy: 0.9715\n",
      "Epoch 120/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0691 - accuracy: 0.9782 - val_loss: 0.1029 - val_accuracy: 0.9692\n",
      "Epoch 121/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0694 - accuracy: 0.9761 - val_loss: 0.1022 - val_accuracy: 0.9708\n",
      "Epoch 122/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0686 - accuracy: 0.9769 - val_loss: 0.1021 - val_accuracy: 0.9708\n",
      "Epoch 123/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0685 - accuracy: 0.9779 - val_loss: 0.1023 - val_accuracy: 0.9708\n",
      "Epoch 124/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0726 - accuracy: 0.9733 - val_loss: 0.1020 - val_accuracy: 0.9708\n",
      "Epoch 125/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0683 - accuracy: 0.9774 - val_loss: 0.1008 - val_accuracy: 0.9738\n",
      "Epoch 126/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0679 - accuracy: 0.9769 - val_loss: 0.1011 - val_accuracy: 0.9731\n",
      "Epoch 127/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0666 - accuracy: 0.9787 - val_loss: 0.1007 - val_accuracy: 0.9731\n",
      "Epoch 128/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0665 - accuracy: 0.9790 - val_loss: 0.1005 - val_accuracy: 0.9723\n",
      "Epoch 129/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0658 - accuracy: 0.9782 - val_loss: 0.0999 - val_accuracy: 0.9746\n",
      "Epoch 130/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0651 - accuracy: 0.9787 - val_loss: 0.1003 - val_accuracy: 0.9708\n",
      "Epoch 131/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0653 - accuracy: 0.9790 - val_loss: 0.1031 - val_accuracy: 0.9700\n",
      "Epoch 132/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0663 - accuracy: 0.9777 - val_loss: 0.0995 - val_accuracy: 0.9731\n",
      "Epoch 133/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0655 - accuracy: 0.9769 - val_loss: 0.0997 - val_accuracy: 0.9715\n",
      "Epoch 134/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0651 - accuracy: 0.9797 - val_loss: 0.1019 - val_accuracy: 0.9731\n",
      "Epoch 135/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0663 - accuracy: 0.9787 - val_loss: 0.1034 - val_accuracy: 0.9700\n",
      "Epoch 136/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 0.1064 - val_accuracy: 0.9685\n",
      "Epoch 137/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0635 - accuracy: 0.9787 - val_loss: 0.1013 - val_accuracy: 0.9723\n",
      "Epoch 138/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0639 - accuracy: 0.9784 - val_loss: 0.1003 - val_accuracy: 0.9731\n",
      "Epoch 139/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0641 - accuracy: 0.9782 - val_loss: 0.0981 - val_accuracy: 0.9731\n",
      "Epoch 140/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0640 - accuracy: 0.9782 - val_loss: 0.0991 - val_accuracy: 0.9731\n",
      "Epoch 141/2000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0664 - accuracy: 0.9769 - val_loss: 0.0971 - val_accuracy: 0.9723\n",
      "Epoch 142/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0623 - accuracy: 0.9792 - val_loss: 0.0972 - val_accuracy: 0.9731\n",
      "Epoch 143/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0604 - accuracy: 0.9792 - val_loss: 0.0973 - val_accuracy: 0.9731\n",
      "Epoch 144/2000\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 0.0606 - accuracy: 0.9800 - val_loss: 0.0971 - val_accuracy: 0.9731\n",
      "Epoch 145/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0606 - accuracy: 0.9805 - val_loss: 0.1013 - val_accuracy: 0.9708\n",
      "Epoch 146/2000\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.0623 - accuracy: 0.9772 - val_loss: 0.0966 - val_accuracy: 0.9738\n",
      "Epoch 147/2000\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0602 - accuracy: 0.9800 - val_loss: 0.0963 - val_accuracy: 0.9738\n",
      "Epoch 148/2000\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.0592 - accuracy: 0.9800 - val_loss: 0.0956 - val_accuracy: 0.9754\n",
      "Epoch 149/2000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0591 - accuracy: 0.9802 - val_loss: 0.0974 - val_accuracy: 0.9731\n",
      "Epoch 150/2000\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.0975 - val_accuracy: 0.9731\n",
      "Epoch 151/2000\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0613 - accuracy: 0.9800 - val_loss: 0.1068 - val_accuracy: 0.9677\n",
      "Epoch 152/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0598 - accuracy: 0.9802 - val_loss: 0.0978 - val_accuracy: 0.9723\n",
      "Epoch 153/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0589 - accuracy: 0.9792 - val_loss: 0.0982 - val_accuracy: 0.9738\n",
      "Epoch 154/2000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 0.0996 - val_accuracy: 0.9738\n",
      "Epoch 155/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0581 - accuracy: 0.9792 - val_loss: 0.0969 - val_accuracy: 0.9731\n",
      "Epoch 156/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0580 - accuracy: 0.9823 - val_loss: 0.0942 - val_accuracy: 0.9738\n",
      "Epoch 157/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0583 - accuracy: 0.9790 - val_loss: 0.0949 - val_accuracy: 0.9746\n",
      "Epoch 158/2000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0585 - accuracy: 0.9802 - val_loss: 0.0949 - val_accuracy: 0.9738\n",
      "Epoch 159/2000\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.0571 - accuracy: 0.9808 - val_loss: 0.0944 - val_accuracy: 0.9738\n",
      "Epoch 160/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0564 - accuracy: 0.9810 - val_loss: 0.0957 - val_accuracy: 0.9738\n",
      "Epoch 161/2000\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.0937 - val_accuracy: 0.9738\n",
      "Epoch 162/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0946 - val_accuracy: 0.9746\n",
      "Epoch 163/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0551 - accuracy: 0.9820 - val_loss: 0.0973 - val_accuracy: 0.9754\n",
      "Epoch 164/2000\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.0931 - val_accuracy: 0.9746\n",
      "Epoch 165/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0555 - accuracy: 0.9813 - val_loss: 0.0931 - val_accuracy: 0.9746\n",
      "Epoch 166/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0542 - accuracy: 0.9808 - val_loss: 0.0934 - val_accuracy: 0.9738\n",
      "Epoch 167/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 0.0932 - val_accuracy: 0.9746\n",
      "Epoch 168/2000\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.0927 - val_accuracy: 0.9754\n",
      "Epoch 169/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.0968 - val_accuracy: 0.9746\n",
      "Epoch 170/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0982 - val_accuracy: 0.9754\n",
      "Epoch 171/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 0.0932 - val_accuracy: 0.9746\n",
      "Epoch 172/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0548 - accuracy: 0.9820 - val_loss: 0.0924 - val_accuracy: 0.9762\n",
      "Epoch 173/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0553 - accuracy: 0.9810 - val_loss: 0.0963 - val_accuracy: 0.9746\n",
      "Epoch 174/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0556 - accuracy: 0.9805 - val_loss: 0.0917 - val_accuracy: 0.9754\n",
      "Epoch 175/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0525 - accuracy: 0.9828 - val_loss: 0.0921 - val_accuracy: 0.9746\n",
      "Epoch 176/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0521 - accuracy: 0.9818 - val_loss: 0.0913 - val_accuracy: 0.9762\n",
      "Epoch 177/2000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 0.0912 - val_accuracy: 0.9762\n",
      "Epoch 178/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0517 - accuracy: 0.9820 - val_loss: 0.0942 - val_accuracy: 0.9746\n",
      "Epoch 179/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.0927 - val_accuracy: 0.9746\n",
      "Epoch 180/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0916 - val_accuracy: 0.9746\n",
      "Epoch 181/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0540 - accuracy: 0.9787 - val_loss: 0.0915 - val_accuracy: 0.9769\n",
      "Epoch 182/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0534 - accuracy: 0.9820 - val_loss: 0.1096 - val_accuracy: 0.9662\n",
      "Epoch 183/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0559 - accuracy: 0.9810 - val_loss: 0.0918 - val_accuracy: 0.9738\n",
      "Epoch 184/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0515 - accuracy: 0.9836 - val_loss: 0.0922 - val_accuracy: 0.9746\n",
      "Epoch 185/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0508 - accuracy: 0.9833 - val_loss: 0.0906 - val_accuracy: 0.9762\n",
      "Epoch 186/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 0.0919 - val_accuracy: 0.9754\n",
      "Epoch 187/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0505 - accuracy: 0.9826 - val_loss: 0.1012 - val_accuracy: 0.9731\n",
      "Epoch 188/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0517 - accuracy: 0.9820 - val_loss: 0.0901 - val_accuracy: 0.9754\n",
      "Epoch 189/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0519 - accuracy: 0.9818 - val_loss: 0.0907 - val_accuracy: 0.9754\n",
      "Epoch 190/2000\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0521 - accuracy: 0.9813 - val_loss: 0.0895 - val_accuracy: 0.9762\n",
      "Epoch 191/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 0.0898 - val_accuracy: 0.9777\n",
      "Epoch 192/2000\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.0502 - accuracy: 0.9833 - val_loss: 0.0896 - val_accuracy: 0.9777\n",
      "Epoch 193/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0491 - accuracy: 0.9836 - val_loss: 0.0889 - val_accuracy: 0.9762\n",
      "Epoch 194/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 0.0891 - val_accuracy: 0.9777\n",
      "Epoch 195/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0502 - accuracy: 0.9838 - val_loss: 0.0902 - val_accuracy: 0.9754\n",
      "Epoch 196/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0486 - accuracy: 0.9843 - val_loss: 0.0889 - val_accuracy: 0.9769\n",
      "Epoch 197/2000\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.0480 - accuracy: 0.9836 - val_loss: 0.0889 - val_accuracy: 0.9754\n",
      "Epoch 198/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0484 - accuracy: 0.9843 - val_loss: 0.0979 - val_accuracy: 0.9754\n",
      "Epoch 199/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0499 - accuracy: 0.9841 - val_loss: 0.0955 - val_accuracy: 0.9754\n",
      "Epoch 200/2000\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0518 - accuracy: 0.9828 - val_loss: 0.0883 - val_accuracy: 0.9769\n",
      "Epoch 201/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0490 - accuracy: 0.9828 - val_loss: 0.0891 - val_accuracy: 0.9754\n",
      "Epoch 202/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0471 - accuracy: 0.9843 - val_loss: 0.0883 - val_accuracy: 0.9754\n",
      "Epoch 203/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0474 - accuracy: 0.9851 - val_loss: 0.0919 - val_accuracy: 0.9762\n",
      "Epoch 204/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 0.0944 - val_accuracy: 0.9762\n",
      "Epoch 205/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0511 - accuracy: 0.9831 - val_loss: 0.0927 - val_accuracy: 0.9762\n",
      "Epoch 206/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0513 - accuracy: 0.9836 - val_loss: 0.0875 - val_accuracy: 0.9769\n",
      "Epoch 207/2000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0473 - accuracy: 0.9841 - val_loss: 0.0871 - val_accuracy: 0.9777\n",
      "Epoch 208/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0465 - accuracy: 0.9841 - val_loss: 0.0872 - val_accuracy: 0.9792\n",
      "Epoch 209/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0481 - accuracy: 0.9843 - val_loss: 0.0878 - val_accuracy: 0.9762\n",
      "Epoch 210/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 0.0957 - val_accuracy: 0.9754\n",
      "Epoch 211/2000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0470 - accuracy: 0.9854 - val_loss: 0.0983 - val_accuracy: 0.9746\n",
      "Epoch 212/2000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0481 - accuracy: 0.9833 - val_loss: 0.0868 - val_accuracy: 0.9777\n",
      "Epoch 213/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0476 - accuracy: 0.9846 - val_loss: 0.0877 - val_accuracy: 0.9792\n",
      "Epoch 214/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0471 - accuracy: 0.9843 - val_loss: 0.0874 - val_accuracy: 0.9762\n",
      "Epoch 215/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0457 - accuracy: 0.9859 - val_loss: 0.0984 - val_accuracy: 0.9754\n",
      "Epoch 216/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 0.1088 - val_accuracy: 0.9685\n",
      "Epoch 217/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0547 - accuracy: 0.9805 - val_loss: 0.0895 - val_accuracy: 0.9762\n",
      "Epoch 218/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0879 - val_accuracy: 0.9785\n",
      "Epoch 219/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0473 - accuracy: 0.9849 - val_loss: 0.0869 - val_accuracy: 0.9769\n",
      "Epoch 220/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0453 - accuracy: 0.9851 - val_loss: 0.0875 - val_accuracy: 0.9769\n",
      "Epoch 221/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0458 - accuracy: 0.9854 - val_loss: 0.0858 - val_accuracy: 0.9808\n",
      "Epoch 222/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0492 - accuracy: 0.9826 - val_loss: 0.0866 - val_accuracy: 0.9792\n",
      "Epoch 223/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.0851 - val_accuracy: 0.9808\n",
      "Epoch 224/2000\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.0449 - accuracy: 0.9851 - val_loss: 0.0850 - val_accuracy: 0.9785\n",
      "Epoch 225/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 0.0930 - val_accuracy: 0.9754\n",
      "Epoch 226/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0505 - accuracy: 0.9833 - val_loss: 0.0856 - val_accuracy: 0.9769\n",
      "Epoch 227/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0527 - accuracy: 0.9818 - val_loss: 0.0942 - val_accuracy: 0.9738\n",
      "Epoch 228/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0517 - accuracy: 0.9843 - val_loss: 0.0891 - val_accuracy: 0.9769\n",
      "Epoch 229/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0465 - accuracy: 0.9854 - val_loss: 0.0848 - val_accuracy: 0.9785\n",
      "Epoch 230/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0440 - accuracy: 0.9856 - val_loss: 0.0871 - val_accuracy: 0.9769\n",
      "Epoch 231/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0444 - accuracy: 0.9843 - val_loss: 0.0851 - val_accuracy: 0.9800\n",
      "Epoch 232/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0468 - accuracy: 0.9846 - val_loss: 0.0893 - val_accuracy: 0.9754\n",
      "Epoch 233/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0482 - accuracy: 0.9849 - val_loss: 0.0852 - val_accuracy: 0.9792\n",
      "Epoch 234/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.0868 - val_accuracy: 0.9769\n",
      "Epoch 235/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0438 - accuracy: 0.9856 - val_loss: 0.0873 - val_accuracy: 0.9769\n",
      "Epoch 236/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0429 - accuracy: 0.9867 - val_loss: 0.0839 - val_accuracy: 0.9808\n",
      "Epoch 237/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0446 - accuracy: 0.9843 - val_loss: 0.0850 - val_accuracy: 0.9792\n",
      "Epoch 238/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 0.0872 - val_accuracy: 0.9769\n",
      "Epoch 239/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0435 - accuracy: 0.9846 - val_loss: 0.0846 - val_accuracy: 0.9785\n",
      "Epoch 240/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0456 - accuracy: 0.9849 - val_loss: 0.0846 - val_accuracy: 0.9800\n",
      "Epoch 241/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0443 - accuracy: 0.9854 - val_loss: 0.0900 - val_accuracy: 0.9762\n",
      "Epoch 242/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0466 - accuracy: 0.9841 - val_loss: 0.0990 - val_accuracy: 0.9746\n",
      "Epoch 243/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0455 - accuracy: 0.9856 - val_loss: 0.0929 - val_accuracy: 0.9762\n",
      "Epoch 244/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0440 - accuracy: 0.9843 - val_loss: 0.0856 - val_accuracy: 0.9792\n",
      "Epoch 245/2000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0433 - accuracy: 0.9851 - val_loss: 0.0834 - val_accuracy: 0.9800\n",
      "Epoch 246/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0483 - accuracy: 0.9838 - val_loss: 0.0906 - val_accuracy: 0.9762\n",
      "Epoch 247/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0429 - accuracy: 0.9859 - val_loss: 0.0899 - val_accuracy: 0.9762\n",
      "Epoch 248/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0430 - accuracy: 0.9864 - val_loss: 0.0867 - val_accuracy: 0.9769\n",
      "Epoch 249/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0439 - accuracy: 0.9851 - val_loss: 0.0920 - val_accuracy: 0.9762\n",
      "Epoch 250/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0416 - accuracy: 0.9851 - val_loss: 0.0860 - val_accuracy: 0.9785\n",
      "Epoch 251/2000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0477 - accuracy: 0.9833 - val_loss: 0.0836 - val_accuracy: 0.9792\n",
      "Epoch 252/2000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0435 - accuracy: 0.9838 - val_loss: 0.0834 - val_accuracy: 0.9792\n",
      "Epoch 253/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0448 - accuracy: 0.9856 - val_loss: 0.0848 - val_accuracy: 0.9769\n",
      "Epoch 254/2000\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0436 - accuracy: 0.9859 - val_loss: 0.1020 - val_accuracy: 0.9738\n",
      "Epoch 255/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0460 - accuracy: 0.9846 - val_loss: 0.0905 - val_accuracy: 0.9762\n",
      "Epoch 256/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0430 - accuracy: 0.9841 - val_loss: 0.0843 - val_accuracy: 0.9785\n",
      "Epoch 257/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0413 - accuracy: 0.9854 - val_loss: 0.0848 - val_accuracy: 0.9785\n",
      "Epoch 258/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0469 - accuracy: 0.9841 - val_loss: 0.0865 - val_accuracy: 0.9762\n",
      "Epoch 259/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0425 - accuracy: 0.9859 - val_loss: 0.0966 - val_accuracy: 0.9762\n",
      "Epoch 260/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0431 - accuracy: 0.9856 - val_loss: 0.0839 - val_accuracy: 0.9777\n",
      "Epoch 261/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.0842 - val_accuracy: 0.9777\n",
      "Epoch 262/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0409 - accuracy: 0.9861 - val_loss: 0.0858 - val_accuracy: 0.9769\n",
      "Epoch 263/2000\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0405 - accuracy: 0.9861 - val_loss: 0.0821 - val_accuracy: 0.9800\n",
      "Epoch 264/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0403 - accuracy: 0.9856 - val_loss: 0.0887 - val_accuracy: 0.9762\n",
      "Epoch 265/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0408 - accuracy: 0.9864 - val_loss: 0.0833 - val_accuracy: 0.9762\n",
      "Epoch 266/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0406 - accuracy: 0.9859 - val_loss: 0.0823 - val_accuracy: 0.9800\n",
      "Epoch 267/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0409 - accuracy: 0.9867 - val_loss: 0.0824 - val_accuracy: 0.9792\n",
      "Epoch 268/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0399 - accuracy: 0.9864 - val_loss: 0.0820 - val_accuracy: 0.9800\n",
      "Epoch 269/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.0826 - val_accuracy: 0.9777\n",
      "Epoch 270/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 0.0829 - val_accuracy: 0.9777\n",
      "Epoch 271/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0404 - accuracy: 0.9861 - val_loss: 0.0823 - val_accuracy: 0.9792\n",
      "Epoch 272/2000\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0411 - accuracy: 0.9854 - val_loss: 0.0817 - val_accuracy: 0.9800\n",
      "Epoch 273/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 0.0822 - val_accuracy: 0.9792\n",
      "Epoch 274/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0413 - accuracy: 0.9867 - val_loss: 0.0820 - val_accuracy: 0.9800\n",
      "Epoch 275/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 0.0856 - val_accuracy: 0.9769\n",
      "Epoch 276/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0397 - accuracy: 0.9856 - val_loss: 0.0834 - val_accuracy: 0.9762\n",
      "Epoch 277/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 0.0930 - val_accuracy: 0.9762\n",
      "Epoch 278/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 0.0839 - val_accuracy: 0.9777\n",
      "Epoch 279/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0398 - accuracy: 0.9867 - val_loss: 0.0860 - val_accuracy: 0.9762\n",
      "Epoch 280/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0396 - accuracy: 0.9869 - val_loss: 0.0816 - val_accuracy: 0.9800\n",
      "Epoch 281/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0387 - accuracy: 0.9869 - val_loss: 0.0847 - val_accuracy: 0.9769\n",
      "Epoch 282/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 0.0828 - val_accuracy: 0.9769\n",
      "Epoch 283/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 0.0827 - val_accuracy: 0.9777\n",
      "Epoch 284/2000\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0392 - accuracy: 0.9864 - val_loss: 0.0813 - val_accuracy: 0.9808\n",
      "Epoch 285/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 0.9864 - val_loss: 0.0816 - val_accuracy: 0.9792\n",
      "Epoch 286/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0403 - accuracy: 0.9885 - val_loss: 0.0819 - val_accuracy: 0.9792\n",
      "Epoch 287/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0428 - accuracy: 0.9854 - val_loss: 0.0865 - val_accuracy: 0.9762\n",
      "Epoch 288/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0397 - accuracy: 0.9867 - val_loss: 0.0863 - val_accuracy: 0.9762\n",
      "Epoch 289/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.0869 - val_accuracy: 0.9762\n",
      "Epoch 290/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0401 - accuracy: 0.9869 - val_loss: 0.0908 - val_accuracy: 0.9762\n",
      "Epoch 291/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0404 - accuracy: 0.9867 - val_loss: 0.0855 - val_accuracy: 0.9762\n",
      "Epoch 292/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0399 - accuracy: 0.9856 - val_loss: 0.0842 - val_accuracy: 0.9769\n",
      "Epoch 293/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 0.0936 - val_accuracy: 0.9769\n",
      "Epoch 294/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 0.0816 - val_accuracy: 0.9777\n",
      "Epoch 295/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0817 - val_accuracy: 0.9808\n",
      "Epoch 296/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 0.0810 - val_accuracy: 0.9808\n",
      "Epoch 297/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.0821 - val_accuracy: 0.9777\n",
      "Epoch 298/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0379 - accuracy: 0.9867 - val_loss: 0.0809 - val_accuracy: 0.9808\n",
      "Epoch 299/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0392 - accuracy: 0.9867 - val_loss: 0.0815 - val_accuracy: 0.9785\n",
      "Epoch 300/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0811 - val_accuracy: 0.9792\n",
      "Epoch 301/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0383 - accuracy: 0.9864 - val_loss: 0.0805 - val_accuracy: 0.9800\n",
      "Epoch 302/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.0815 - val_accuracy: 0.9792\n",
      "Epoch 303/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0381 - accuracy: 0.9874 - val_loss: 0.0882 - val_accuracy: 0.9754\n",
      "Epoch 304/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0379 - accuracy: 0.9867 - val_loss: 0.0816 - val_accuracy: 0.9808\n",
      "Epoch 305/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.0851 - val_accuracy: 0.9762\n",
      "Epoch 306/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0387 - accuracy: 0.9869 - val_loss: 0.0809 - val_accuracy: 0.9808\n",
      "Epoch 307/2000\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0393 - accuracy: 0.9859 - val_loss: 0.0803 - val_accuracy: 0.9808\n",
      "Epoch 308/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0379 - accuracy: 0.9861 - val_loss: 0.0811 - val_accuracy: 0.9800\n",
      "Epoch 309/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 0.0816 - val_accuracy: 0.9808\n",
      "Epoch 310/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.0856 - val_accuracy: 0.9754\n",
      "Epoch 311/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 0.0862 - val_accuracy: 0.9762\n",
      "Epoch 312/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0375 - accuracy: 0.9867 - val_loss: 0.0809 - val_accuracy: 0.9808\n",
      "Epoch 313/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0376 - accuracy: 0.9859 - val_loss: 0.0804 - val_accuracy: 0.9808\n",
      "Epoch 314/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0367 - accuracy: 0.9859 - val_loss: 0.0840 - val_accuracy: 0.9762\n",
      "Epoch 315/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0372 - accuracy: 0.9867 - val_loss: 0.0846 - val_accuracy: 0.9769\n",
      "Epoch 316/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0364 - accuracy: 0.9877 - val_loss: 0.0804 - val_accuracy: 0.9800\n",
      "Epoch 317/2000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0396 - accuracy: 0.9864 - val_loss: 0.0805 - val_accuracy: 0.9792\n",
      "Epoch 318/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 0.0872 - val_accuracy: 0.9754\n",
      "Epoch 319/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0399 - accuracy: 0.9846 - val_loss: 0.0921 - val_accuracy: 0.9777\n",
      "Epoch 320/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0401 - accuracy: 0.9874 - val_loss: 0.0980 - val_accuracy: 0.9754\n",
      "Epoch 321/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 0.0824 - val_accuracy: 0.9777\n",
      "Epoch 322/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0460 - accuracy: 0.9836 - val_loss: 0.0837 - val_accuracy: 0.9808\n",
      "Epoch 323/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.0835 - val_accuracy: 0.9800\n",
      "Epoch 324/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0406 - accuracy: 0.9864 - val_loss: 0.0817 - val_accuracy: 0.9800\n",
      "Epoch 325/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0375 - accuracy: 0.9859 - val_loss: 0.0836 - val_accuracy: 0.9769\n",
      "Epoch 326/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0360 - accuracy: 0.9869 - val_loss: 0.0812 - val_accuracy: 0.9792\n",
      "Epoch 327/2000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0362 - accuracy: 0.9879 - val_loss: 0.0799 - val_accuracy: 0.9815\n",
      "Epoch 328/2000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0371 - accuracy: 0.9872 - val_loss: 0.0806 - val_accuracy: 0.9800\n",
      "Epoch 329/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0366 - accuracy: 0.9869 - val_loss: 0.0807 - val_accuracy: 0.9808\n",
      "Epoch 330/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9867 - val_loss: 0.0818 - val_accuracy: 0.9800\n",
      "Epoch 331/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.0830 - val_accuracy: 0.9762\n",
      "Epoch 332/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0359 - accuracy: 0.9879 - val_loss: 0.0904 - val_accuracy: 0.9769\n",
      "Epoch 333/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 0.0802 - val_accuracy: 0.9808\n",
      "Epoch 334/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 0.0805 - val_accuracy: 0.9815\n",
      "Epoch 335/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0410 - accuracy: 0.9851 - val_loss: 0.0823 - val_accuracy: 0.9808\n",
      "Epoch 336/2000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0401 - accuracy: 0.9869 - val_loss: 0.0796 - val_accuracy: 0.9815\n",
      "Epoch 337/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0364 - accuracy: 0.9867 - val_loss: 0.0801 - val_accuracy: 0.9815\n",
      "Epoch 338/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0355 - accuracy: 0.9882 - val_loss: 0.0866 - val_accuracy: 0.9762\n",
      "Epoch 339/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0377 - accuracy: 0.9856 - val_loss: 0.0865 - val_accuracy: 0.9769\n",
      "Epoch 340/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0361 - accuracy: 0.9879 - val_loss: 0.0830 - val_accuracy: 0.9769\n",
      "Epoch 341/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0358 - accuracy: 0.9874 - val_loss: 0.0812 - val_accuracy: 0.9800\n",
      "Epoch 342/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0390 - accuracy: 0.9859 - val_loss: 0.0833 - val_accuracy: 0.9769\n",
      "Epoch 343/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0364 - accuracy: 0.9864 - val_loss: 0.0798 - val_accuracy: 0.9815\n",
      "Epoch 344/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0354 - accuracy: 0.9877 - val_loss: 0.0820 - val_accuracy: 0.9777\n",
      "Epoch 345/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0359 - accuracy: 0.9872 - val_loss: 0.0847 - val_accuracy: 0.9769\n",
      "Epoch 346/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0825 - val_accuracy: 0.9769\n",
      "Epoch 347/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.0945 - val_accuracy: 0.9769\n",
      "Epoch 348/2000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.0853 - val_accuracy: 0.9777\n",
      "Epoch 349/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0353 - accuracy: 0.9874 - val_loss: 0.0801 - val_accuracy: 0.9792\n",
      "Epoch 350/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0355 - accuracy: 0.9872 - val_loss: 0.0895 - val_accuracy: 0.9769\n",
      "Epoch 351/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 0.0954 - val_accuracy: 0.9769\n",
      "Epoch 352/2000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.1060 - val_accuracy: 0.9746\n",
      "Epoch 353/2000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.0868 - val_accuracy: 0.9762\n",
      "Epoch 354/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0357 - accuracy: 0.9874 - val_loss: 0.0847 - val_accuracy: 0.9769\n",
      "Epoch 355/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0361 - accuracy: 0.9869 - val_loss: 0.0893 - val_accuracy: 0.9754\n",
      "Epoch 356/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0366 - accuracy: 0.9877 - val_loss: 0.0806 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb4be90790>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#중단점과 저장 설정\n",
    "early_stopping_callback = EarlyStopping(patience=20)\n",
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=0, save_best_only=True)\n",
    "                               \n",
    "\n",
    "# 모델 실행 : callbacks 를 설정 \n",
    "model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25,\n",
    "         callbacks=[ early_stopping_callback,checkpointer])                               \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec59ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
